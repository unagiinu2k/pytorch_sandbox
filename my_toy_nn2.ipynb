{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "git add my_toy_nn2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "git commit -a -m \"checkpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.cuda.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gist.github.com/santi-pdp/d0e9002afe74db04aa5bbff6d076e8fe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 正解がゼロとイチであるような100個のデータを作る\n",
    "* ゼロの方よりイチのほうがすべての座標の平均が1.5大きい"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]  ='0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which device we want to run on\n",
    "ngpu = 1\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = torch.randn(1000, 50)\n",
    "X2 = torch.randn(1000, 50) + 1.5\n",
    "X3 = torch.randn(1000,50) + 3\n",
    "X = torch.cat([X1, X2 , X3], dim=0)\n",
    "Y1 = torch.zeros(1000, 1)\n",
    "Y2 = torch.ones(1000, 1)\n",
    "Y3 = torch.zeros(1000 , 1)\n",
    "Y = torch.cat([Y1, Y2, Y3], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.size())\n",
    "print(Y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = fig.add_subplot(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1.scatter(X1[:,0] , X1[:,2] , color = \"yellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1.scatter(X2[:,0] , X2[:,2], color = \"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1.scatter(X3[:,0] , X3[:,2] , color = \"yellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ネットワークの定義"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$    \\text{PReLU}(x) = \\max(0,x) + a * \\min(0,x)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features=50, out_features=50)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        #self.dout = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(50, 100)\n",
    "        self.prelu = nn.PReLU(1)\n",
    "        self.out = nn.Linear(100, 1)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        y = self.fc1(input_)\n",
    "        y = self.relu1(y)        \n",
    "        y = self.fc2(y)\n",
    "        y = self.prelu(y)\n",
    "        y = self.out(y)\n",
    "        y = self.out_act(y)\n",
    "        return y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 線形変換 (値が0,1間に入らないのでcriteriaを評価できずエラーになる)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(50, 1)\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        y = self.fc1(input_)\n",
    "        \n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  線形変換＋sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(50, 1)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        a1 = self.fc1(input_)\n",
    "        y = self.out_act(a1)\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## もともとのモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(50, 50)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dout = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(50, 100)\n",
    "        self.prelu = nn.PReLU(1)\n",
    "        self.out = nn.Linear(100, 1)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        a1 = self.fc1(input_)\n",
    "        h1 = self.relu1(a1)\n",
    "        dout = self.dout(h1)\n",
    "        a2 = self.fc2(dout)\n",
    "        h2 = self.prelu(a2)\n",
    "        a3 = self.out(h2)\n",
    "        y = self.out_act(a3)\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習測度はここで指定する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning rate次第で学習の成否が大きく異なってくる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ふたつの確率分布$p,q$があったときクロスエントロピーは\n",
    "\n",
    "$$\n",
    "H(p,q) =-{\\rm E}_p[\\log(q)]\n",
    "$$\n",
    "\n",
    "で定義される"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "説明変数のsample \n",
    "$$\n",
    "x_0,x_1,\\cdots , x_{N-1}\n",
    "$$\n",
    "に対して、正解が１であり、NNが確率$z$で１であると出力したとき、\n",
    "正解の確率分布は\n",
    "\n",
    "\n",
    "$$\n",
    " p(x) =\n",
    " \\begin{cases}\n",
    "        1 & x = 1\\\\\n",
    "        0 & x = 0\n",
    " \\end{cases}\n",
    "$$\n",
    "NNの導いた確率分布は\n",
    "$$\n",
    " q(x) =\n",
    " \\begin{cases}\n",
    "        z & x = 1\\\\\n",
    "        1-z & x = 0\n",
    " \\end{cases}\n",
    "$$\n",
    "なのでクロスエントロピーは\n",
    "$$\n",
    "H(p,q) = -\\log(z)\n",
    "$$\n",
    "であるが、\n",
    "$$\n",
    "H(q,p) = -z \\log(1) - (1-z) \\log(0)\n",
    "$$\n",
    "は計算できない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# my training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training modeに"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_batch(X , Y , batch_size):\n",
    "    for beg_i in range(0, X.size(0), batch_size):\n",
    "        x_batch = X[beg_i:beg_i + batch_size, :]\n",
    "        y_batch = Y[beg_i:beg_i + batch_size, :]\n",
    "        x_batch = Variable(x_batch)\n",
    "        y_batch = Variable(y_batch)\n",
    "        yield x_batch  ,y_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_one_epoch(model , opt, criterion, X , Y , batch_size):\n",
    "    batch_iterator = yield_batch(X , Y  , batch_size)\n",
    "    for x_batch , y_batch in batch_iterator:\n",
    "\n",
    "        ## loop decomposed\n",
    "\n",
    "        ### zero grad\n",
    "        #毎回gradをクリアしないといけない\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        ### Forward\n",
    "\n",
    "        y_hat = model(x_batch)\n",
    "\n",
    "        ### Compute diff\n",
    "\n",
    "        loss = criterion(y_hat, y_batch)\n",
    "        #print(\"loss : {}\".format(loss))\n",
    "\n",
    "        ### Compute gradients\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        ### update weights\n",
    "\n",
    "        opt.step()        \n",
    "\n",
    "        ### loss \n",
    "\n",
    "        run_loss = float(loss.data.numpy())\n",
    "\n",
    "    print(run_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "for i in range(n_epochs):\n",
    "    my_one_epoch(model , opt, criterion, X , Y , batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  答え合わせ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_model = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = fig.add_subplot(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.numpy()[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1.scatter(Y.numpy()[:,0] , y_model.detach().numpy()[:,0] , color = \"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = y_model.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decomposed training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_iterator = yield_batch(X , Y  , batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch , y_batch = next(batch_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loop decomposed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zero grad\n",
    "毎回gradをクリアしないといけない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model(x_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(y_hat, y_batch)\n",
    "print(\"loss : {}\".format(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.step()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_loss = float(loss.data.numpy())\n",
    "\n",
    "print(run_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def train_epoch(model, opt, criterion, batch_size=50):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for beg_i in range(0, X.size(0), batch_size):\n",
    "        x_batch = X[beg_i:beg_i + batch_size, :]\n",
    "        y_batch = Y[beg_i:beg_i + batch_size, :]\n",
    "        x_batch = Variable(x_batch)\n",
    "        y_batch = Variable(y_batch)\n",
    "\n",
    "\n",
    "        opt.zero_grad()\n",
    "        # (1) Forward\n",
    "        y_hat = net(x_batch)\n",
    "        # (2) Compute diff\n",
    "        loss = criterion(y_hat, y_batch)\n",
    "        # (3) Compute gradients\n",
    "        loss.backward()\n",
    "        # (4) update weights\n",
    "        opt.step()        \n",
    "        losses.append(loss.data.numpy())\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_losses = []\n",
    "num_epochs = 200\n",
    "for e in range(num_epochs):\n",
    "    e_losses += train_epoch(net, opt, criterion)\n",
    "plt.plot(e_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "for beg_i in range(0, X.size(0), batch_size):\n",
    "    x_batch = X[beg_i:beg_i + batch_size, :]\n",
    "    y_batch = Y[beg_i:beg_i + batch_size, :]\n",
    "    x_batch = Variable(x_batch)\n",
    "    y_batch = Variable(y_batch)\n",
    "\n",
    "    opt.zero_grad()\n",
    "    # (1) Forward\n",
    "    y_hat = net(x_batch)\n",
    "    # (2) Compute diff\n",
    "    loss = criterion(y_hat, y_batch)\n",
    "    # (3) Compute gradients\n",
    "    loss.backward()\n",
    "    # (4) update weights\n",
    "    opt.step()        \n",
    "    losses.append(loss.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss.backward?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch(net, opt, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# option pricing imitation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import QuantLib as ql "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cl_call:\n",
    "    def price(self , spot_price, strike_price, maturity , is_american = True):\n",
    "        if maturity <= 0:\n",
    "            exercise_value = np.max([0 , spot_price - strike_price])\n",
    "            return (exercise_value)\n",
    "        dummy_strike = strike_price / spot_price\n",
    "        \n",
    "\n",
    "        option_type = ql.Option.Call\n",
    "        payoff = ql.PlainVanillaPayoff(option_type, dummy_strike)\n",
    "        \n",
    "        maturity_date = self.calculation_date + int(365.0 * maturity)\n",
    "        settlement = self.calculation_date\n",
    "        if is_american:\n",
    "            run_exercise = ql.AmericanExercise(settlement, maturity_date)\n",
    "        else:\n",
    "            run_exercise = ql.EuropeanExercise(maturity_date)\n",
    "                \n",
    "        \n",
    "        american_option = ql.VanillaOption(payoff, run_exercise)\n",
    "        if is_american:\n",
    "            american_option.setPricingEngine(self.binomial_engine)\n",
    "        else:\n",
    "\n",
    "            american_option.setPricingEngine(ql.AnalyticEuropeanEngine(self.bsm_process))\n",
    "                \n",
    "        ql.Settings.instance().evaluationDate = self.calculation_date\n",
    "\n",
    "        return (american_option.NPV() * spot_price)\n",
    "        \n",
    "\n",
    "    def __init__(self , volatility , dividend_rate , risk_free_rate  ,steps):\n",
    "        day_count = ql.Actual365Fixed()\n",
    "        #calendar = ql.UnitedStates()\n",
    "        calendar = ql.Japan()\n",
    "        self.calculation_date = ql.Date(8, 5, 2015)\n",
    "        dummy_spot = 1\n",
    "        \n",
    "        self.spot_handle = ql.QuoteHandle(ql.SimpleQuote(1.0))\n",
    "\n",
    "        ql.Settings.instance().evaluationDate = self.calculation_date\n",
    "\n",
    "\n",
    "        self.flat_ts = ql.YieldTermStructureHandle(\n",
    "            ql.FlatForward(self.calculation_date, risk_free_rate, day_count)\n",
    "        )\n",
    "\n",
    "        self.dividend_yield = ql.YieldTermStructureHandle(\n",
    "            ql.FlatForward(self.calculation_date, dividend_rate, day_count)\n",
    "        )\n",
    "\n",
    "        #### volatility\n",
    "\n",
    "        self.flat_vol_ts = ql.BlackVolTermStructureHandle(\n",
    "            ql.BlackConstantVol(self.calculation_date, calendar, volatility, day_count)\n",
    "        )\n",
    "\n",
    "        #### BS framework\n",
    "\n",
    "        self.bsm_process = ql.BlackScholesMertonProcess(self.spot_handle, \n",
    "                                                   self.dividend_yield, \n",
    "                                                   self.flat_ts, \n",
    "                                                   self.flat_vol_ts)\n",
    "\n",
    "\n",
    "        self.binomial_engine = ql.BinomialVanillaEngine(self.bsm_process, \"crr\", steps)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_price = 127.62\n",
    "volatility = 0.20 # the historical vols or implied vols\n",
    "dividend_rate =  0.063\n",
    "risk_free_rate = 0.001\n",
    "maturity = 1\n",
    "dt = 0.1\n",
    "\n",
    "strike_price = 130\n",
    "\n",
    "#steps = 200\n",
    "pricer_steps = 100\n",
    "\n",
    "#dt = maturity / steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_call = cl_call(volatility ,  dividend_rate ,  risk_free_rate , pricer_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_call.price(spot_price, strike_price, maturity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_call.price(130 , 100, 0.1 , True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_call.price(130 , 100 , 0.1,  False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_call.price(130 , 100 , 0.1 , True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_prices  = torch.rand(N, 1) * 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "volatilities = torch.rand(N , 1) * 0.6 + 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dividend_rates= torch.rand(N , 1) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.603355407714844"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "share_prices[0,0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "option_prices = [cl_call(volatilities[i , 0].item() ,  \n",
    "                         dividend_rates[i , 0].item() ,  \n",
    "                         risk_free_rate , \n",
    "                         pricer_steps).price(share_prices[i,0].item(), \n",
    "                                              strike_price, \n",
    "                                              maturity) for i in range(N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.cat([share_prices , volatilities , dividend_rates] , dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(option_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/docs/stable/nn.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 線形モデルはきつい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, 1)\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        y = self.fc1(input_)\n",
    "        \n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reluをつかいつつ中間層をそれなりに大きくするとわりと性能が良い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(3, 50)\n",
    "        self.a1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(50 , 1)\n",
    "    def forward(self, input_, **kwargs):\n",
    "        y = self.fc1(input_)\n",
    "        y = self.a1(y)\n",
    "        y = self.fc2(y)\n",
    "        \n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### softplusモデルも同様に良い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(3, 30 , True)\n",
    "        self.a1 = nn.Softplus()\n",
    "        self.fc2 = nn.Linear(30 , 1)\n",
    "    def forward(self, input_):\n",
    "        y = self.fc1(input_)\n",
    "        y = self.a1(y)\n",
    "        y = self.fc2(y)\n",
    "        \n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=3, out_features=50, bias=True)\n",
      "  (a1): ReLU()\n",
      "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[An overview of gradient descent optimization algorithms](http://ruder.io/optimizing-gradient-descent/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define loss function\n",
    "https://medium.com/udacity-pytorch-challengers/a-brief-overview-of-loss-functions-in-pytorch-c0ddb78068f7\n",
    "\n",
    "[official doc](https://pytorch.org/docs/stable/optim.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=3, out_features=50, bias=True)\n",
       "  (a1): ReLU()\n",
       "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, opt, criterion, X, Y , batch_size=50):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for beg_i in range(0, X.size(0), batch_size):\n",
    "        x_batch = X[beg_i:beg_i + batch_size, :]\n",
    "        y_batch = Y[beg_i:beg_i + batch_size, :]\n",
    "        x_batch = Variable(x_batch)\n",
    "        y_batch = Variable(y_batch)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        # (1) Forward\n",
    "        y_hat = model(x_batch)\n",
    "        # (2) Compute diff\n",
    "        loss = criterion(y_hat, y_batch)\n",
    "        # (3) Compute gradients\n",
    "        loss.backward()\n",
    "        # (4) update weights\n",
    "        opt.step()        \n",
    "        losses.append(loss.data.numpy())\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_losses = []\n",
    "num_epochs = 3000\n",
    "for e in range(num_epochs):\n",
    "    e_losses += train_epoch(model, opt, criterion , X , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0cf70384a8>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(e_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_model = model(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot with bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.plotting as bp\n",
    "from bokeh import palettes\n",
    "bp.output_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = bp.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.scatter(share_prices.numpy()[:,0] , y.numpy()[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.scatter(share_prices.numpy()[:,0] , y_model.detach().numpy()[:,0] , fill_color = \"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = bp.figure()\n",
    "p.scatter(y.numpy()[:,0] , y_model.detach().numpy()[:,0])\n",
    "bp.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = bp.figure()\n",
    "previous_y = run_y\n",
    "run_y = y_model.detach().numpy()[:,0] - y.numpy()[:,0]\n",
    "\n",
    "p.scatter(y.numpy()[:,0] , previous_y , color = 'yellow')\n",
    "p.scatter(y.numpy()[:,0] , run_y)\n",
    "bp.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = bp.figure()\n",
    "#previous_y = run_y\n",
    "#run_y = y_model.detach().numpy()[:,0] - y.numpy()[:,0]\n",
    "\n",
    "p.scatter(run_y , previous_y )\n",
    "#p.scatter(y.numpy()[:,0] , run_y)\n",
    "bp.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check results with matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = fig.add_subplot(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1.scatter(y.numpy()[:,0] , y_model.detach().numpy()[:,0] , color = \"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# skorch-based cross validation (forwardの引数をinputとtargetにするのがポイント）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(3, 50)\n",
    "        self.a1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(50 , 1)\n",
    "    def forward(self, input, target = None):\n",
    "        y = self.fc1(input)\n",
    "        y = self.a1(y)\n",
    "        y = self.fc2(y)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetRegressor\n",
    "\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting without L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_model = NeuralNetRegressor(\n",
    "  model,            # ここで、先程定義したNetクラスを引数として与える\n",
    "  max_epochs=10,\n",
    "  optimizer=optim.Adam,\n",
    "  lr=0.001,\n",
    "  device=device,\n",
    "  batch_size=128,\n",
    "  # デフォルトだと入力データの2割が検証に使われる。入力データすべてを学習に使うためには、以下の通りにする\n",
    "  # train_split=None,\n",
    "  criterion= nn.MSELoss    # CNNの最後のactivationがlog_softmaxなので、lossはNLLoss。\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_model = NeuralNetRegressor(\n",
    "  model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_model.set_params(# ここで、先程定義したNetクラスを引数として与える\n",
    "  max_epochs=10,\n",
    "  optimizer=optim.Adam,\n",
    "  lr=0.001,\n",
    "  device=device,\n",
    "  batch_size=128,\n",
    "  # デフォルトだと入力データの2割が検証に使われる。入力データすべてを学習に使うためには、以下の通りにする\n",
    "  # train_split=None,\n",
    "  criterion= nn.MSELoss    # CNNの最後のactivationがlog_softmaxなので、lossはNLLoss。\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "scores = cross_val_score(wrapped_model, X.numpy(), y.numpy(), cv=5) \n",
    "print(\"elapsed : {}\".format(time.time() -start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting withL1 regularization\n",
    "\n",
    "https://skorch.readthedocs.io/en/latest/user/neuralnet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegularizedNet(NeuralNetRegressor):\n",
    "    def __init__(self, l1_penalty = 0, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        #self.lambda1 = lambda1\n",
    "        self.l1_penalty = 0.0\n",
    "        self.l1_penalty = l1_penalty\n",
    "    def set_l1_penalty(self , l1_penalty):\n",
    "        self.l1_penalty = l1_penalty\n",
    "        \n",
    "\n",
    "\n",
    "    def get_loss(self, y_pred, y_true, X=None, training=False):\n",
    "        loss = super().get_loss(y_pred, y_true, X=X, training=training)\n",
    "        regularization_loss = 0\n",
    "        for param in self.module.parameters():\n",
    "            regularization_loss += torch.sum(torch.abs(param))\n",
    "        #loss += self.lambda1 * sum([w.abs().sum() for w in self.module_.parameters()])\n",
    "        loss = loss + regularization_loss * self.l1_penalty\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二段階定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_model = RegularizedNet(module =   model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_model.set_params(# ここで、先程定義したNetクラスを引数として与える\n",
    "  max_epochs=10,\n",
    "  optimizer=optim.Adam,\n",
    "  lr=0.001,\n",
    "  device=device,\n",
    "  batch_size=128,\n",
    "  # デフォルトだと入力データの2割が検証に使われる。入力データすべてを学習に使うためには、以下の通りにする\n",
    "  # train_split=None,\n",
    "  criterion= nn.MSELoss   , # CNNの最後のactivationがlog_softmaxなので、lossはNLLoss。\n",
    "    verbose = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一段階initialization (走らせ方は同じ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_model = RegularizedNet(\n",
    "  module = model,            # ここで、先程定義したNetクラスを引数として与える\n",
    "  max_epochs=10,\n",
    "  optimizer=optim.Adam,\n",
    "  lr=0.001,\n",
    "  device=device,\n",
    "  batch_size=128,\n",
    "  # デフォルトだと入力データの2割が検証に使われる。入力データすべてを学習に使うためには、以下の通りにする\n",
    "  # train_split=None,\n",
    "  criterion= nn.MSELoss  ,  # CNNの最後のactivationがlog_softmaxなので、lossはNLLoss。\n",
    "    verbose = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysis with sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.numpy() , y.numpy(), test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = preprocessing.StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tmp = scaler.inverse_transform(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tmp == X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_model.set_l1_penalty(10)\n",
    "wrapped_model.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in wrapped_model.module.named_parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "wrapped_model.set_l1_penalty(0.1)\n",
    "scores = cross_val_score(wrapped_model, X_train, y_train, cv=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check various penalties manually (not recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalties = [0,0.0001 , 0.001 , 0.01 , 0.1 , 1, 10, 100 , 1000]\n",
    "score_means = list()\n",
    "for run_penalty in penalties:\n",
    "    wrapped_model.set_l1_penalty(run_penalty)\n",
    "    scores = cross_val_score(wrapped_model, X_train, y_train, cv=5) \n",
    "    score_mean = np.mean(scores)\n",
    "    score_means += [score_mean]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tuning hyperparameters with sklearn\n",
    "https://scikit-learn.org/stable/modules/grid_search.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'l1_penalty':[0,0.001,0.1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(wrapped_model , param_grid , cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# skorchに頼らないcross validation(まだうまく動作していない)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn 準拠の予測モデルのつくりかた\n",
    "https://nykergoto.hatenablog.jp/entry/2017/05/14/003503"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wrap_model(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    分類器のサンプル\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model , opt , criterion , batch_size):\n",
    "        \"\"\"\n",
    "        分類器のコンストラクタ\n",
    "        全部の引数に初期値を与えること !!\n",
    "        \n",
    "        :param int int_val:\n",
    "        :param float sigma:\n",
    "        :param str hogevalue:\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.opt = opt\n",
    "        self.criterion = criterion\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "         \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        データへのフィッティングを行うメソッド。\n",
    "        すべての加工, パラメータの確認はここで定義する。\n",
    "        Note: `assert`よりも`try/exception`を用いるほうが本当は良い. けどめんどうなのでassert使ってます\n",
    "        \n",
    "        :param numpy.ndarray X: 2-D array. 訓練特徴\n",
    "        :param numpy.ndarray y: 1-D array. ターゲット変数\n",
    "        :return: self\n",
    "        :rtype: SampleClassifer\n",
    "        \"\"\"\n",
    "        #assert(isinstance(self.int_val, int) or isinstance(self.int_val, np.int64)), \"int_valは整数値でないと駄目です. \"\n",
    "        #self.treshold_ = (sum(X)/len(X)) + self.int_val\n",
    "        #return self  # return selfするのが慣習\n",
    "    \n",
    "        train_epoch(self.model, self.opt, self.criterion, torch.Tensor(X), torch.Tensor(y) , batch_size= self.batch_size)\n",
    "        return self \n",
    "    \n",
    "\n",
    "        \n",
    "    def predict(self, X, y=None):\n",
    "        \"\"\"\n",
    "        予測を行う\n",
    "        :param numpy.ndarray X: 特徴量. 2-D array\n",
    "        :param numpy.ndarray y: ターゲット変数. 分類問題なので使わないけど`y=None`でおいておく\n",
    "        :return: 1-D array\n",
    "        :rtype: np.ndarray\n",
    "        \"\"\"\n",
    "        #try:\n",
    "        #    getattr(self, \"treshold_\")\n",
    "        #except AttributeError:\n",
    "        #    raise RuntimeError(\"モデルは訓練されていません\")\n",
    "        ty = self.model(torch.Tensor(X))\n",
    "        y = ty.detach().numpy()\n",
    "        return y\n",
    "        #return ([self._meaning(x) for x in X])\n",
    "    \n",
    "    def score(self, X, y=None):\n",
    "        \"\"\"\n",
    "        モデルの良さを数値化する\n",
    "        なんでもいいけれど、大きい方が良くて、小さいほうがだめ。\n",
    "        今回は平均以上の値がいくつあるかをスコアとして定義する。\n",
    "        \n",
    "        :return: 平均値の値よりも大きい数\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return (sum(self.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_model = wrap_model(model , opt , criterion , batch_size  = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(wrapped_model, X.numpy(), y.numpy(), cv=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleClassifer(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    分類器のサンプル\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, int_val=0, sigma=.5, hogevalue=None):\n",
    "        \"\"\"\n",
    "        分類器のコンストラクタ\n",
    "        全部の引数に初期値を与えること !!\n",
    "        \n",
    "        :param int int_val:\n",
    "        :param float sigma:\n",
    "        :param str hogevalue:\n",
    "        \"\"\"\n",
    "        self.int_val = int_val\n",
    "        self.sigma = sigma\n",
    "        self.hogevalue = hogevalue\n",
    "        self.huga = hogevalue  # 引数とインスタンス変数の名前が違っている. 非推奨. \n",
    "         \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        データへのフィッティングを行うメソッド。\n",
    "        すべての加工, パラメータの確認はここで定義する。\n",
    "        Note: `assert`よりも`try/exception`を用いるほうが本当は良い. けどめんどうなのでassert使ってます\n",
    "        \n",
    "        :param numpy.ndarray X: 2-D array. 訓練特徴\n",
    "        :param numpy.ndarray y: 1-D array. ターゲット変数\n",
    "        :return: self\n",
    "        :rtype: SampleClassifer\n",
    "        \"\"\"\n",
    "        assert(isinstance(self.int_val, int) or isinstance(self.int_val, np.int64)), \"int_valは整数値でないと駄目です. \"\n",
    "        self.treshold_ = (sum(X)/len(X)) + self.int_val\n",
    "        return self  # return selfするのが慣習\n",
    "    \n",
    "    def _meaning(self, x):\n",
    "        \"\"\"\n",
    "        平均値よりも大きければTrueを返す分類\n",
    "        :rtype: bool\n",
    "        \"\"\"\n",
    "        if x > self.treshold_:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def predict(self, X, y=None):\n",
    "        \"\"\"\n",
    "        予測を行う\n",
    "        :param numpy.ndarray X: 特徴量. 2-D array\n",
    "        :param numpy.ndarray y: ターゲット変数. 分類問題なので使わないけど`y=None`でおいておく\n",
    "        :return: 1-D array\n",
    "        :rtype: np.ndarray\n",
    "        \"\"\"\n",
    "        try:\n",
    "            getattr(self, \"treshold_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"モデルは訓練されていません\")\n",
    "            \n",
    "        return ([self._meaning(x) for x in X])\n",
    "    \n",
    "    def score(self, X, y=None):\n",
    "        \"\"\"\n",
    "        モデルの良さを数値化する\n",
    "        なんでもいいけれど、大きい方が良くて、小さいほうがだめ。\n",
    "        今回は平均以上の値がいくつあるかをスコアとして定義する。\n",
    "        \n",
    "        :return: 平均値の値よりも大きい数\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return (sum(self.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot with plotnine\n",
    "\n",
    "https://www.kaggle.com/princeashburton/an-intro-to-plotnine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mNeuralNetRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'torch.nn.modules.loss.MSELoss'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "NeuralNet for regression tasks\n",
       "\n",
       "Use this specifically if you have a standard regression task,\n",
       "with input data X and target y. y must be 2d.\n",
       "\n",
       "In addition to the parameters listed below, there are parameters\n",
       "with specific prefixes that are handled separately. To illustrate\n",
       "this, here is an example:\n",
       "\n",
       ">>> net = NeuralNet(\n",
       "...    ...,\n",
       "...    optimizer=torch.optimizer.SGD,\n",
       "...    optimizer__momentum=0.95,\n",
       "...)\n",
       "\n",
       "This way, when ``optimizer`` is initialized, :class:`.NeuralNet`\n",
       "will take care of setting the ``momentum`` parameter to 0.95.\n",
       "\n",
       "(Note that the double underscore notation in\n",
       "``optimizer__momentum`` means that the parameter ``momentum``\n",
       "should be set on the object ``optimizer``. This is the same\n",
       "semantic as used by sklearn.)\n",
       "\n",
       "Furthermore, this allows to change those parameters later:\n",
       "\n",
       "``net.set_params(optimizer__momentum=0.99)``\n",
       "\n",
       "This can be useful when you want to change certain parameters\n",
       "using a callback, when using the net in an sklearn grid search,\n",
       "etc.\n",
       "\n",
       "By default an :class:`.EpochTimer`, :class:`.BatchScoring` (for\n",
       "both training and validation datasets), and :class:`.PrintLog`\n",
       "callbacks are installed for the user's convenience.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "module : torch module (class or instance)\n",
       "  A PyTorch :class:`~torch.nn.Module`. In general, the\n",
       "  uninstantiated class should be passed, although instantiated\n",
       "  modules will also work.\n",
       "\n",
       "criterion : torch criterion (class, default=torch.nn.MSELoss)\n",
       "  Mean squared error loss.\n",
       "\n",
       "optimizer : torch optim (class, default=torch.optim.SGD)\n",
       "  The uninitialized optimizer (update rule) used to optimize the\n",
       "  module\n",
       "\n",
       "lr : float (default=0.01)\n",
       "  Learning rate passed to the optimizer. You may use ``lr`` instead\n",
       "  of using ``optimizer__lr``, which would result in the same outcome.\n",
       "\n",
       "max_epochs : int (default=10)\n",
       "  The number of epochs to train for each ``fit`` call. Note that you\n",
       "  may keyboard-interrupt training at any time.\n",
       "\n",
       "batch_size : int (default=128)\n",
       "  Mini-batch size. Use this instead of setting\n",
       "  ``iterator_train__batch_size`` and ``iterator_test__batch_size``,\n",
       "  which would result in the same outcome. If ``batch_size`` is -1,\n",
       "  a single batch with all the data will be used during training\n",
       "  and validation.\n",
       "\n",
       "iterator_train : torch DataLoader\n",
       "  The default PyTorch :class:`~torch.utils.data.DataLoader` used for\n",
       "  training data.\n",
       "\n",
       "iterator_valid : torch DataLoader\n",
       "  The default PyTorch :class:`~torch.utils.data.DataLoader` used for\n",
       "  validation and test data, i.e. during inference.\n",
       "\n",
       "dataset : torch Dataset (default=skorch.dataset.Dataset)\n",
       "  The dataset is necessary for the incoming data to work with\n",
       "  pytorch's ``DataLoader``. It has to implement the ``__len__`` and\n",
       "  ``__getitem__`` methods. The provided dataset should be capable of\n",
       "  dealing with a lot of data types out of the box, so only change\n",
       "  this if your data is not supported. You should generally pass the\n",
       "  uninitialized ``Dataset`` class and define additional arguments to\n",
       "  X and y by prefixing them with ``dataset__``. It is also possible\n",
       "  to pass an initialzed ``Dataset``, in which case no additional\n",
       "  arguments may be passed.\n",
       "\n",
       "train_split : None or callable (default=skorch.dataset.CVSplit(5))\n",
       "  If None, there is no train/validation split. Else, train_split\n",
       "  should be a function or callable that is called with X and y\n",
       "  data and should return the tuple ``dataset_train, dataset_valid``.\n",
       "  The validation data may be None.\n",
       "\n",
       "callbacks : None or list of Callback instances (default=None)\n",
       "  More callbacks, in addition to those returned by\n",
       "  ``get_default_callbacks``. Each callback should inherit from\n",
       "  :class:`.Callback`. If not ``None``, a list of callbacks is\n",
       "  expected where the callback names are inferred from the class\n",
       "  name. Name conflicts are resolved by appending a count suffix\n",
       "  starting with 1, e.g. ``EpochScoring_1``. Alternatively,\n",
       "  a tuple ``(name, callback)`` can be passed, where ``name``\n",
       "  should be unique. Callbacks may or may not be instantiated.\n",
       "  The callback name can be used to set parameters on specific\n",
       "  callbacks (e.g., for the callback with name ``'print_log'``, use\n",
       "  ``net.set_params(callbacks__print_log__keys_ignored=['epoch',\n",
       "  'train_loss'])``).\n",
       "\n",
       "warm_start : bool (default=False)\n",
       "  Whether each fit call should lead to a re-initialization of the\n",
       "  module (cold start) or whether the module should be trained\n",
       "  further (warm start).\n",
       "\n",
       "verbose : int (default=1)\n",
       "  Control the verbosity level.\n",
       "\n",
       "device : str, torch.device (default='cpu')\n",
       "  The compute device to be used. If set to 'cuda', data in torch\n",
       "  tensors will be pushed to cuda tensors before being sent to the\n",
       "  module.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "prefixes_ : list of str\n",
       "  Contains the prefixes to special parameters. E.g., since there\n",
       "  is the ``'module'`` prefix, it is possible to set parameters like\n",
       "  so: ``NeuralNet(..., optimizer__momentum=0.95)``.\n",
       "\n",
       "cuda_dependent_attributes_ : list of str\n",
       "  Contains a list of all attribute prefixes whose values depend on a\n",
       "  CUDA device. If a ``NeuralNet`` trained with a CUDA-enabled device\n",
       "  is unpickled on a machine without CUDA or with CUDA disabled, the\n",
       "  listed attributes are mapped to CPU.  Expand this list if you\n",
       "  want to add other cuda-dependent attributes.\n",
       "\n",
       "initialized_ : bool\n",
       "  Whether the :class:`.NeuralNet` was initialized.\n",
       "\n",
       "module_ : torch module (instance)\n",
       "  The instantiated module.\n",
       "\n",
       "criterion_ : torch criterion (instance)\n",
       "  The instantiated criterion.\n",
       "\n",
       "callbacks_ : list of tuples\n",
       "  The complete (i.e. default and other), initialized callbacks, in\n",
       "  a tuple with unique names.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/base2/lib/python3.7/site-packages/skorch/regressor.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?NeuralNetRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super(Model, self).__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "           x = F.relu(self.conv1(x))\n",
       "           return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/base2/lib/python3.7/site-packages/torch/nn/modules/module.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     Identity, Linear, Bilinear, _ConvNd, Threshold, ReLU, RReLU, Hardtanh, Sigmoid, Tanh, ...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_get_name',\n",
       " '_load_from_state_dict',\n",
       " '_named_members',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_slow_forward',\n",
       " '_tracing_name',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'half',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_parameter',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'train',\n",
       " 'type',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "194px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
