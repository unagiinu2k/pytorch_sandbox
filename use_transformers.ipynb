{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/huggingface/transformers#quick-tour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [(BertModel,       BertTokenizer,       'bert-base-uncased'),\n",
    "          (OpenAIGPTModel,  OpenAIGPTTokenizer,  'openai-gpt'),\n",
    "          (GPT2Model,       GPT2Tokenizer,       'gpt2')\n",
    "      #    (CTRLModel,       CTRLTokenizer,       'ctrl'),\n",
    "      #    (TransfoXLModel,  TransfoXLTokenizer,  'transfo-xl-wt103'),\n",
    "      #    (XLNetModel,      XLNetTokenizer,      'xlnet-base-cased'),\n",
    "      #    (XLMModel,        XLMTokenizer,        'xlm-mlm-enfr-1024'),\n",
    "      #    (DistilBertModel, DistilBertTokenizer, 'distilbert-base-cased'),\n",
    "      #    (RobertaModel,    RobertaTokenizer,    'roberta-base'),\n",
    "       #   (XLMRobertaModel, XLMRobertaTokenizer, 'xlm-roberta-base'),\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for model_class, tokenizer_class, pretrained_weights in MODELS:\n",
    "    # Load pretrained model/tokenizer\n",
    "    tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "    model = model_class.from_pretrained(pretrained_weights)\n",
    "\n",
    "    # Encode text\n",
    "    input_ids = torch.tensor([tokenizer.encode(\"Here is some text to encode\", add_special_tokens=True)])  # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(input_ids)[0]  # Models outputs are now tuples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, pretrained_weights  = MODELS[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how to extract all hidden states and all attentions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/transformers/main_classes/tokenizer.html\n",
    "　\n",
    "tokenizer.encodeは\n",
    "```python\n",
    "run_phrase = [\"This is the first sentence.\" , \"And a next sentence follows\"]\n",
    "```\n",
    "みたいなのは食えない模様"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.forwardのアウトプットがどういうtupleかは\n",
    "https://huggingface.co/transformers/model_doc/bert.html\n",
    "を参照\n",
    "- last hidden states\n",
    "- pooler output\n",
    "- hidden states\n",
    "- attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_phrase = \"Periods are also tokenized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_phrase = \"Ski\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_phrase = \"because BERT uses sentencepiece, sometimes the number of tokens is larger than word counts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode text\n",
    "tokenized = tokenizer.encode(run_phrase, add_special_tokens=True)\n",
    "input_ids = torch.tensor([tokenized])  # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids)[0]  # Models outputs are now tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 4106]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20545]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenizer \n",
    "\n",
    "https://huggingface.co/transformers/main_classes/tokenizer.html\n",
    "\n",
    "https://huggingface.co/transformers/model_doc/bert.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### どのように分割されたかのチェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['international', 'ization']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(tokenizer.encode(\"internationalization\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [45609, 1634],\n",
       " 'token_type_ids': [0, 0],\n",
       " 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode_plus(\"internationalization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## last hiddenベクトルの性質チェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = model_class.from_pretrained(pretrained_weights, torchscript=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_last_hidden_dict(run_phrase):\n",
    "\n",
    "    tokenized = tokenizer.encode(run_phrase, add_special_tokens=True)\n",
    "    input_ids = torch.tensor([tokenized])  # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(input_ids)[0]  # Models outputs are now tuples\n",
    "        \n",
    "    tokens = tokenizer.convert_ids_to_tokens(tokenized)\n",
    "    run_dict = {tokens[i] : last_hidden_states[:,i,:].squeeze().numpy() for i in range(len(tokens))}\n",
    "    return run_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多分語頭と語尾に相当するtokenが存在する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ski'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_last_hidden_dict(\"ski\").keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[CLS]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-71dab826de74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_last_hidden_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ski is fun.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'[CLS]'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: '[CLS]'"
     ]
    }
   ],
   "source": [
    "tmp = my_last_hidden_dict(\"Ski is fun.\")['[CLS]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ski'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-cdf7abd35a77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_last_hidden_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ski\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ski'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mmy_last_hidden_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Snow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'snow'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'ski'"
     ]
    }
   ],
   "source": [
    "sp.spatial.distance.cosine(my_last_hidden_dict(\"Ski\")['ski'] ,my_last_hidden_dict(\"Snow\")['snow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snowboardは2語に分割される\n",
    "sp.spatial.distance.cosine(my_last_hidden_dict(\"Ski\")['ski'] ,my_last_hidden_dict(\"Snowboard\")['snowboard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowboard = my_last_hidden_dict(\"Snowboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.spatial.distance.cosine(my_last_hidden_dict(\"Ski\")['ski'] ,snowboard[\"snow\"] + snowboard[\"##board\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.spatial.distance.cosine(my_last_hidden_dict(\"Ski\")['ski'] ,snowboard[\"##board\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.spatial.distance.cosine(my_last_hidden_dict(\"Ski\")['ski'] , my_last_hidden_dict(\"world ski championship\")['ski'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.spatial.distance.cosine(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.spatial.distance.cosine(my_last_hidden_dict(\"Ski\")['ski'] , my_last_hidden_dict(\"soccer\")['soccer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.spatial.distance.cosine(my_last_hidden_dict(\"Ski\")['ski'] , my_last_hidden_dict(\"sugar\")['sugar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.spatial.distance.cosine(my_last_hidden_dict(\"Ski\")['ski'] , my_last_hidden_dict(\"freestyle ski\")['ski'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wordpieceにより分割されていると思われる例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_last_hidden_dict(\"internationalization\").keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## その他のレイヤーのベクトルの性質チェック\n",
    "ゼロから順番に深いレイヤーなことに注意。\n",
    "https://github.com/huggingface/transformers/issues/1950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models can return full list of hidden-states & attentions weights at each layer\n",
    "model = model_class.from_pretrained(pretrained_weights,\n",
    "                                    output_hidden_states=True,\n",
    "                                    output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "index out of range at /opt/conda/conda-bld/pytorch_1556653114079/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:193",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-0bffdafb0137>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Let's see all hidden-states and attentions on this text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mall_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_attentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/xeus/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xeus/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m         embedding_output = self.embeddings(\n\u001b[0;32m--> 802\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m         )\n\u001b[1;32m    804\u001b[0m         encoder_outputs = self.encoder(\n",
      "\u001b[0;32m~/anaconda3/envs/xeus/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xeus/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xeus/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xeus/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m         return F.embedding(\n\u001b[1;32m    116\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xeus/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1506\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index out of range at /opt/conda/conda-bld/pytorch_1556653114079/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:193"
     ]
    }
   ],
   "source": [
    "input_ids = torch.tensor([tokenizer.encode(\"Let's see all hidden-states and attentions on this text\")])\n",
    "all_hidden_states, all_attentions = model(input_ids)[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_hidden_dict(run_phrase , layer = 0):\n",
    "\n",
    "    tokenized = tokenizer.encode(run_phrase, add_special_tokens=True)\n",
    "    input_ids = torch.tensor([tokenized])  # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n",
    "    with torch.no_grad():\n",
    "        all_hidden_states, all_attentions = model(input_ids)[-2:]\n",
    "        #last_hidden_states = model(input_ids)[0]  # Models outputs are now tuples\n",
    "        \n",
    "    tokens = tokenizer.convert_ids_to_tokens(tokenized)\n",
    "    run_dict = {tokens[i] : all_hidden_states[layer][:,i,:].squeeze().numpy() for i in range(len(tokens))}\n",
    "    return run_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一番浅いレイヤーでもかなり文脈依存になってしまっている\n",
    "l = -1\n",
    "sp.spatial.distance.cosine(my_hidden_dict('ski' , l)['ski'] ,my_hidden_dict('freestyle ski', l)['ski'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03874468803405762"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "l = 0\n",
    "sp.spatial.distance.cosine(my_hidden_dict('ski' , l)['ski'] ,my_hidden_dict('freestyle ski', l)['ski'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最初のembedding処理後のベクトルの性質チェック\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_embedding_dict(run_phrase , layer = 0):\n",
    "\n",
    "    tokenized = tokenizer.encode(run_phrase, add_special_tokens=True)\n",
    "    input_ids = torch.tensor([tokenized])  # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n",
    "    with torch.no_grad():\n",
    "        all_hidden_states, all_attentions = model(input_ids)[-2:]\n",
    "        #last_hidden_states = model(input_ids)[0]  # Models outputs are now tuples\n",
    "    embed_matrix = model.get_input_embeddings().weight\n",
    "    tokens = tokenizer.convert_ids_to_tokens(tokenized)\n",
    "    run_dict = {tokens[i] : embed_matrix[tokenized[i],:].detach().squeeze().numpy() for i in range(len(tokens))}\n",
    "    return run_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.spatial.distance.cosine(my_embedding_dict('ski' , l)['ski'] ,my_embedding_dict('freestyle ski', l)['ski'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.36629464e-03, -8.62949193e-02, -5.18712401e-03, -2.91774143e-02,\n",
       "       -9.84724239e-02,  1.92878749e-02, -6.35578185e-02,  2.71245721e-03,\n",
       "       -4.84481268e-02, -6.00291006e-02, -2.70059016e-02, -1.24797113e-01,\n",
       "        6.52698847e-03,  8.33721459e-02,  5.17042279e-02, -4.73624393e-02,\n",
       "       -1.08939119e-01, -1.66100613e-03,  3.23905535e-02, -2.55150665e-02,\n",
       "       -8.46075267e-02, -3.65849547e-02, -2.20447723e-02, -6.00817576e-02,\n",
       "       -1.01680659e-01,  6.35808706e-03, -5.35597503e-02, -8.54655206e-02,\n",
       "       -1.04875557e-01, -3.55551876e-02, -3.13782953e-02,  4.86183092e-02,\n",
       "       -2.48831343e-02,  4.24876101e-02, -9.63180698e-03,  6.49224967e-03,\n",
       "       -2.72310916e-02,  4.13084356e-03, -1.12589009e-01,  4.29117419e-02,\n",
       "        9.25005879e-03, -3.73848341e-02, -7.25976937e-03, -1.18009374e-01,\n",
       "       -7.50806406e-02,  6.07025996e-03, -3.97465825e-02,  1.08596459e-02,\n",
       "       -1.86708961e-02, -5.58486348e-03, -2.33931001e-02,  7.82739837e-03,\n",
       "       -1.80814657e-02, -8.72684736e-03, -5.95663264e-02, -1.20196899e-03,\n",
       "       -3.05897351e-02, -4.27873693e-02, -4.40283157e-02,  3.10529489e-03,\n",
       "       -1.21270143e-03,  1.31531963e-02,  5.77901863e-02, -3.33852060e-02,\n",
       "       -6.33006692e-02,  2.75819600e-02, -3.81614268e-02,  7.14730565e-03,\n",
       "       -2.49893963e-02, -2.44494621e-02, -3.55334952e-02,  5.74994460e-02,\n",
       "        5.73676173e-03, -1.14594311e-01, -2.11025681e-02,  2.14878209e-02,\n",
       "       -9.35982689e-02,  3.11650932e-02, -2.29419321e-02,  1.34833157e-03,\n",
       "        2.67585739e-02, -3.94674391e-02,  1.71620920e-02,  2.13429946e-02,\n",
       "       -7.82020390e-03, -4.73807119e-02, -4.74216137e-03, -5.58061637e-02,\n",
       "       -8.81206617e-03, -1.09676324e-01, -5.61786592e-02,  2.02930495e-02,\n",
       "       -2.42478158e-02, -9.64858569e-03, -4.36530970e-02, -1.37475729e-02,\n",
       "        1.01208031e-01, -5.77346198e-02, -1.44818351e-02, -3.72823179e-02,\n",
       "       -4.52595614e-02, -1.85834467e-02, -1.13768866e-02, -8.73024315e-02,\n",
       "       -5.18242791e-02,  5.28357103e-02,  1.99241401e-03,  3.87157798e-02,\n",
       "        2.17036828e-02, -7.10334033e-02,  1.28691783e-02, -7.56561570e-03,\n",
       "       -3.70174125e-02, -6.62960187e-02, -5.42909019e-02,  1.93218254e-02,\n",
       "       -5.06051779e-02, -1.36001678e-02, -4.66670934e-03, -8.69830623e-02,\n",
       "        3.02337240e-02,  6.86078370e-02, -1.26945302e-02, -7.17916489e-02,\n",
       "       -2.59412192e-02, -4.56777662e-02, -8.51267204e-02, -5.30219004e-02,\n",
       "        3.55320349e-02, -1.00535080e-01,  1.90514978e-02,  2.79831933e-03,\n",
       "       -9.29645170e-03, -6.13971576e-02,  1.07578393e-02, -6.19590580e-02,\n",
       "       -1.16120540e-02,  3.65018323e-02, -1.31790891e-01,  7.75961280e-02,\n",
       "       -2.29930524e-02, -7.23392293e-02, -1.35826087e-02, -2.23066788e-02,\n",
       "       -2.78252121e-02, -2.58281734e-02, -1.03423484e-01, -1.03059791e-01,\n",
       "       -2.73290258e-02, -1.03153056e-02, -2.09776592e-02, -6.05308563e-02,\n",
       "       -7.57889450e-02, -4.66382317e-02, -9.08290520e-02,  1.11815939e-02,\n",
       "        6.40379116e-02, -1.10442020e-01, -5.31346984e-02, -1.42038256e-01,\n",
       "        1.07572163e-02, -7.15276897e-02, -2.37202980e-02,  1.95701257e-03,\n",
       "       -7.46476231e-03, -7.67320488e-03,  1.43751381e-02, -8.80816430e-02,\n",
       "        1.35139758e-02, -6.67215884e-02, -5.20863570e-03, -9.61059704e-03,\n",
       "       -7.48545397e-03, -3.63469422e-02, -4.65242639e-02,  9.99098942e-02,\n",
       "       -3.45591716e-02, -6.03101403e-03, -8.02484807e-03, -6.97100861e-03,\n",
       "       -7.98707083e-02, -1.00617092e-02, -2.16823742e-02,  7.57582486e-02,\n",
       "       -6.48687175e-03,  1.68418828e-02,  3.05833798e-02, -6.43303245e-02,\n",
       "       -4.52745780e-02, -8.62521082e-02, -3.93287726e-02, -2.77609136e-02,\n",
       "       -2.14160159e-02,  2.18254291e-02, -7.97797069e-02, -1.95452683e-02,\n",
       "       -6.82908818e-02, -4.56134230e-02, -3.87699045e-02, -4.27122116e-02,\n",
       "       -7.59295747e-02, -8.26770216e-02, -1.68748349e-02,  3.49243078e-03,\n",
       "        2.17970461e-03,  3.61917280e-02, -4.09684367e-02, -6.73852339e-02,\n",
       "       -4.43729982e-02,  6.84036082e-03, -1.71878580e-02,  5.67893637e-03,\n",
       "       -2.16920804e-02,  2.11780835e-02,  3.13904546e-02, -6.17717430e-02,\n",
       "       -1.27584651e-01, -3.99176814e-02, -5.68971261e-02, -5.10753915e-02,\n",
       "       -9.70354676e-02, -5.67639172e-02, -7.94859156e-02,  9.34501830e-03,\n",
       "        9.28714778e-03, -1.16012571e-02,  4.53304574e-02, -5.60082532e-02,\n",
       "       -3.11627612e-02,  3.96335572e-02,  1.13555500e-02,  2.03159582e-02,\n",
       "       -2.75038201e-02, -1.48872985e-02,  3.25402096e-02,  7.64657604e-03,\n",
       "       -1.21259786e-01,  3.13951783e-02,  1.73001792e-02,  5.67589030e-02,\n",
       "       -1.13217179e-02,  1.10435691e-02, -2.02095155e-02, -5.26364967e-02,\n",
       "       -3.17652710e-02,  1.22439424e-02,  1.70133244e-02, -5.41687198e-03,\n",
       "        1.42737404e-02, -1.36183798e-01, -3.74890678e-02, -4.12457511e-02,\n",
       "       -5.18185552e-03, -2.74311863e-02, -5.71606681e-02,  5.72832562e-02,\n",
       "       -6.57307059e-02, -5.98896034e-02, -8.21914151e-02, -3.83168049e-02,\n",
       "       -7.40026608e-02, -3.16462144e-02, -1.43681187e-02, -1.85094718e-02,\n",
       "       -7.94651061e-02,  3.26728523e-02,  2.62119714e-03, -1.77587941e-02,\n",
       "       -6.91267848e-02, -8.33251998e-02,  1.58319008e-02, -5.49625605e-02,\n",
       "       -4.26989347e-02,  1.74125694e-02,  2.59500612e-02,  1.52068939e-02,\n",
       "        5.22078089e-02, -1.11894205e-01, -1.25501873e-02, -6.72749504e-02,\n",
       "       -9.35842395e-02,  8.45067203e-03, -1.03031196e-01, -5.33252433e-02,\n",
       "       -2.41827108e-02, -8.06415528e-02, -9.89036784e-02,  3.51733854e-03,\n",
       "       -5.50912619e-02, -4.06798534e-02, -1.69550013e-02, -1.42503465e-02,\n",
       "        4.94439080e-02,  5.17308246e-03, -6.55553862e-02,  1.81710664e-02,\n",
       "        8.17453116e-03, -4.51829247e-02, -2.00193152e-02,  3.41476202e-02,\n",
       "       -3.09296395e-03, -1.58176608e-02, -3.23185399e-02,  5.15411235e-03,\n",
       "       -4.53621782e-02,  4.84899571e-03, -3.88208665e-02, -1.54244741e-02,\n",
       "        4.76375334e-02, -1.10036314e-01, -3.98054011e-02,  6.63656592e-02,\n",
       "       -4.42462787e-02, -5.56885265e-02, -3.83866988e-02,  1.60533581e-02,\n",
       "       -2.48050783e-02,  8.14481732e-03, -5.05100898e-02,  4.69351262e-02,\n",
       "       -1.94024332e-02, -1.69087469e-03, -3.41962576e-02,  1.00554721e-02,\n",
       "       -1.97524745e-02,  8.38888343e-03, -1.02224402e-01, -8.22704956e-02,\n",
       "        1.99511703e-02,  8.99765640e-02, -9.27076489e-02, -2.03705169e-02,\n",
       "        1.52147654e-02,  6.87675327e-02, -5.34912311e-02, -1.14246868e-02,\n",
       "       -4.76025790e-02, -3.74509916e-02,  6.12548366e-02,  6.74903169e-02,\n",
       "        3.55643854e-02,  1.60622653e-02,  1.19113142e-03, -5.62876724e-02,\n",
       "       -6.11297786e-02,  2.50686612e-02, -3.96940038e-02, -4.62284721e-02,\n",
       "       -3.96028608e-02,  5.82063459e-02,  1.69154108e-02, -2.26544384e-02,\n",
       "       -1.46170286e-02,  3.37495655e-02, -4.78282943e-02, -6.01257831e-02,\n",
       "        6.41907975e-02, -5.43001704e-02, -2.62224525e-02, -1.23128533e-01,\n",
       "       -3.47809382e-02,  1.89922936e-02, -4.08986062e-02,  8.25325400e-03,\n",
       "        1.83039568e-02, -3.82995456e-02, -1.21640511e-01, -8.34586248e-02,\n",
       "       -2.69099064e-02, -1.89238228e-02, -5.13527617e-02, -6.17952049e-02,\n",
       "       -7.59603456e-03, -9.07704458e-02, -5.47420932e-03,  2.07345281e-02,\n",
       "       -2.94722505e-02, -6.53491393e-02, -4.55801450e-02, -2.61345953e-02,\n",
       "        3.35578690e-03, -4.46545891e-02,  1.76472403e-02, -4.74248640e-02,\n",
       "        7.53702745e-02, -9.06016491e-03, -4.58009355e-02,  1.80228148e-02,\n",
       "        3.36216092e-02,  2.34583784e-02, -5.87621778e-02,  4.95226458e-02,\n",
       "       -5.47270402e-02,  6.63706064e-02, -2.79559363e-02, -3.36141549e-02,\n",
       "       -4.68673976e-03,  3.56669761e-02, -8.27532262e-02,  1.25785610e-02,\n",
       "        8.12728982e-03, -1.33598372e-01,  9.82129015e-03, -9.58052406e-04,\n",
       "        6.64676249e-04,  2.77985092e-02,  2.76994538e-02, -1.16858117e-01,\n",
       "       -3.46500389e-02, -1.04389876e-01,  7.59364665e-03, -9.27155539e-02,\n",
       "        1.98098812e-02, -3.51711400e-02, -2.66182460e-02,  2.92614126e-03,\n",
       "        2.64253933e-02,  2.70306654e-02, -5.41048609e-02, -5.79581000e-02,\n",
       "       -9.11080372e-03, -6.02094866e-02, -2.12118328e-02, -1.64946225e-02,\n",
       "       -7.40927979e-02, -7.30591686e-03, -6.49176314e-02, -6.53599575e-02,\n",
       "       -3.17134671e-02, -7.99264461e-02, -9.75965243e-03, -2.89177373e-02,\n",
       "       -2.65491270e-02, -5.21111563e-02, -2.44562645e-02, -9.48947296e-02,\n",
       "       -3.97223188e-03,  1.76923275e-02,  6.69785310e-03,  9.62205883e-03,\n",
       "       -4.23567072e-02,  3.37815448e-03, -1.62983220e-02,  5.33293076e-02,\n",
       "       -1.05841942e-02, -3.76046859e-02, -5.73769249e-02, -4.33943346e-02,\n",
       "        4.49007899e-02, -4.34279218e-02, -2.36609615e-02, -3.76606770e-02,\n",
       "       -4.88014193e-03, -4.79228273e-02, -4.11228128e-02, -9.13867503e-02,\n",
       "       -1.08060099e-01,  8.00729077e-03, -2.63670906e-02, -1.64115112e-02,\n",
       "       -1.28581692e-02,  6.19979650e-02,  2.36888081e-02,  8.11638965e-05,\n",
       "       -1.43523654e-02, -3.57303629e-03,  2.37694290e-02,  1.08560920e-02,\n",
       "        1.40086394e-02, -5.91272637e-02, -1.21475630e-01, -1.89254489e-02,\n",
       "        2.26111710e-02,  1.78014999e-03,  2.36155260e-02,  3.03272400e-02,\n",
       "       -3.76161635e-02, -2.79769674e-02, -4.06801961e-02,  1.89425051e-02,\n",
       "       -5.69766276e-02, -3.96115286e-03,  2.00596731e-02, -3.02171111e-02,\n",
       "       -7.51792789e-02,  3.92817520e-02, -5.87423742e-02, -4.13326640e-03,\n",
       "        4.59847413e-03, -4.27822098e-02, -2.82585677e-02, -1.01908185e-02,\n",
       "       -3.57438251e-02, -7.66941682e-02, -2.91300062e-02, -3.01485579e-03,\n",
       "       -1.27406267e-04, -1.77071355e-02, -3.45199034e-02, -4.89199273e-02,\n",
       "       -6.51004314e-02, -4.48391511e-04,  2.16434374e-02, -8.13136846e-02,\n",
       "        3.29184569e-02,  7.53271254e-03, -7.38163218e-02,  1.72975007e-02,\n",
       "       -5.84572405e-02, -7.47018829e-02, -6.78359196e-02, -2.82557774e-02,\n",
       "        2.97471341e-02,  1.01819830e-02, -1.94382854e-02,  1.10782008e-03,\n",
       "       -5.52008301e-02,  9.51877013e-02,  3.42546329e-02, -2.81107798e-02,\n",
       "        1.39609315e-02, -1.62168909e-02, -8.37702081e-02, -4.33837324e-02,\n",
       "       -4.66036685e-02, -4.98803593e-02, -5.17348684e-02, -8.76894146e-02,\n",
       "       -4.30793241e-02,  1.71576720e-02, -7.23531544e-02, -3.46205160e-02,\n",
       "        6.10769214e-03,  2.01410335e-02,  3.04301623e-02,  6.08147234e-02,\n",
       "        1.10081593e-02, -1.43896043e-02, -1.62119288e-02, -7.32626095e-02,\n",
       "        4.42521647e-02,  8.70215148e-02,  2.68299133e-03, -7.37563372e-02,\n",
       "       -8.65622386e-02,  4.40763757e-02,  2.05303375e-02, -8.70787501e-02,\n",
       "       -3.45862284e-02,  1.58878248e-02, -1.12343825e-01, -7.14147016e-02,\n",
       "       -2.71609407e-02, -2.10177302e-02, -2.04903521e-02, -4.26911153e-02,\n",
       "        1.97810549e-02, -3.79069224e-02, -5.52706458e-02,  2.83385832e-02,\n",
       "       -1.79167185e-02, -3.85810174e-02, -2.70616338e-02, -4.77345586e-02,\n",
       "        2.29922626e-02, -9.31011736e-02,  1.89288054e-02, -6.39241263e-02,\n",
       "       -6.49982095e-02, -1.65582225e-02, -6.20041117e-02, -1.03075713e-01,\n",
       "       -1.59248020e-02, -9.38043464e-03, -8.85729957e-03,  6.61971630e-04,\n",
       "        3.94453481e-02,  3.45635880e-03,  5.84700704e-02,  1.52325574e-02,\n",
       "       -1.26029514e-02, -3.19379121e-02, -1.14662208e-01,  1.13504184e-02,\n",
       "       -2.54931934e-02,  6.64689541e-02, -5.73320780e-03,  1.25947746e-03,\n",
       "       -3.11111324e-02, -6.37047738e-02,  1.63923725e-02,  2.08828915e-02,\n",
       "       -5.44052050e-02, -3.16135399e-02,  3.66289057e-02,  1.34999892e-02,\n",
       "       -4.41265479e-02, -4.23094071e-02, -5.35350032e-02,  6.11275528e-03,\n",
       "       -4.48732860e-02,  2.31963093e-03, -4.51189540e-02, -2.11454593e-02,\n",
       "       -3.63047011e-02,  3.47856246e-02, -7.25495443e-02, -3.60990874e-02,\n",
       "       -3.27265188e-02,  1.88233741e-02, -5.54654412e-02, -4.84931562e-03,\n",
       "       -1.88642312e-02, -9.48912464e-03, -6.87295645e-02, -5.51295802e-02,\n",
       "       -2.80622076e-02, -4.10944521e-02,  3.56798768e-02,  7.74962306e-02,\n",
       "       -5.12779318e-02, -1.75653789e-02, -1.06228748e-02, -3.80828120e-02,\n",
       "        7.34789297e-02, -9.88388062e-02, -7.81000257e-02, -4.94395569e-02,\n",
       "       -9.83825773e-02, -2.43535242e-03,  3.83594483e-02, -6.71362653e-02,\n",
       "       -2.89412569e-02, -2.89917961e-02, -5.96132269e-03,  2.56283339e-02,\n",
       "       -4.06406447e-02, -8.46346989e-02, -1.99073441e-02, -2.11499520e-02,\n",
       "       -2.86958180e-02, -1.03796564e-01,  1.44226055e-04, -3.43330093e-02,\n",
       "        3.34751010e-02, -7.16328667e-03, -7.41767883e-02, -1.79373603e-02,\n",
       "       -7.04024062e-02, -5.84103912e-02,  2.63287965e-02, -4.00974974e-02,\n",
       "       -8.75813514e-02, -6.06424361e-02,  4.87057380e-02,  3.31327654e-02,\n",
       "       -5.68609033e-03,  1.44448280e-02, -1.96320973e-02, -6.14821352e-02,\n",
       "        5.97379054e-04,  1.54247526e-02, -8.16261396e-02,  6.95951730e-02,\n",
       "       -5.84723726e-02,  4.90886625e-04, -6.56667253e-05, -8.24998841e-02,\n",
       "       -6.59141615e-02,  1.61598320e-03,  1.15220221e-02, -4.13669534e-02,\n",
       "        1.04779203e-03, -1.26373783e-01, -4.17753570e-02, -3.34437448e-03,\n",
       "        1.28943911e-02, -4.19479124e-02,  4.77359705e-02, -4.10211496e-02,\n",
       "       -5.12046739e-02,  9.54485126e-03, -3.82837318e-02,  2.10540034e-02,\n",
       "        3.07616815e-02, -1.30625308e-01,  3.27541456e-02,  3.43452836e-03,\n",
       "       -7.32220188e-02,  2.45128740e-02, -7.38038495e-02,  1.40525457e-02,\n",
       "       -4.85745072e-03, -1.91146508e-02, -4.04879935e-02, -1.08013421e-01,\n",
       "       -3.94329317e-02, -5.02429903e-02, -1.14112861e-01,  2.46816147e-02,\n",
       "        4.90982970e-03, -1.35612823e-02, -8.90656635e-02, -5.68811893e-02,\n",
       "       -1.36382990e-02, -3.81515697e-02, -4.36207056e-02,  3.48702967e-02,\n",
       "       -3.54019441e-02, -1.40095465e-02,  1.47515247e-02, -1.01713076e-01,\n",
       "       -4.07155193e-02, -5.48792332e-02, -7.19395950e-02, -3.99748348e-02,\n",
       "       -4.72355299e-02, -9.55620036e-02, -9.53376219e-02, -5.05541712e-02,\n",
       "       -5.82286641e-02, -7.75576159e-02, -6.78703003e-03,  3.17123495e-02,\n",
       "       -5.14901169e-02,  1.39302351e-02,  8.29924345e-02, -2.08790563e-02,\n",
       "       -4.15189601e-02, -1.10673970e-02, -6.38119364e-03,  5.06654661e-03,\n",
       "        3.22687742e-03, -7.34415874e-02, -6.41588196e-02,  2.89424211e-02,\n",
       "       -6.70750672e-03, -7.77585758e-03, -9.67168510e-02,  1.71792675e-02,\n",
       "       -3.56468670e-02,  1.06941843e-02,  4.52569015e-02,  2.16214787e-02,\n",
       "       -6.97311759e-02, -7.16276746e-03, -4.11513820e-02, -5.61736450e-02,\n",
       "       -2.33325772e-02, -5.86498249e-03, -2.01604469e-03, -7.50496844e-03,\n",
       "       -2.59242319e-02, -6.70075929e-03, -1.20930344e-01,  1.12897754e-02,\n",
       "       -7.73964822e-02, -1.54829528e-02, -3.38907279e-02, -1.52126281e-02,\n",
       "        1.60139648e-03, -7.63054863e-02,  3.00871544e-02, -1.37407118e-02,\n",
       "       -8.56447220e-02, -5.79610355e-02, -3.39891464e-02, -5.04779927e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_embedding_dict(\"Ski\")[\"ski\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.sparse.Embedding"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.get_input_embeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30522, 768])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_input_embeddings().weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 未分類\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_last_hidden(\"baseball\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each architecture is provided with several class for fine-tuning on down-stream tasks, e.g.\n",
    "BERT_MODEL_CLASSES = [BertModel, BertForPreTraining, BertForMaskedLM, BertForNextSentencePrediction,\n",
    "                      BertForSequenceClassification, BertForTokenClassification, BertForQuestionAnswering]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = BERT_MODEL_CLASSES[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models can return full list of hidden-states & attentions weights at each layer\n",
    "model = model_class.from_pretrained(pretrained_weights,\n",
    "                                    output_hidden_states=True,\n",
    "                                    output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([tokenizer.encode(\"Let's see all hidden-states and attentions on this text\")])\n",
    "all_hidden_states, all_attentions = model(input_ids)[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backend', '_backward_hooks', '_buffers', '_do_output_past', '_forward_hooks', '_forward_pre_hooks', '_generate_beam_search', '_generate_no_beam_search', '_get_name', '_get_resized_embeddings', '_init_weights', '_load_from_state_dict', '_load_state_dict_pre_hooks', '_modules', '_named_members', '_parameters', '_prune_heads', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_resize_token_embeddings', '_slow_forward', '_state_dict_hooks', '_tie_or_clone_weights', '_tracing_name', '_version', 'add_module', 'apply', 'base_model', 'base_model_prefix', 'buffers', 'children', 'config', 'config_class', 'cpu', 'cuda', 'double', 'dummy_inputs', 'dump_patches', 'embeddings', 'encoder', 'eval', 'extra_repr', 'float', 'forward', 'from_pretrained', 'generate', 'get_input_embeddings', 'get_output_embeddings', 'half', 'init_weights', 'load_state_dict', 'load_tf_weights', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'num_parameters', 'parameters', 'pooler', 'prepare_inputs_for_generation', 'pretrained_model_archive_map', 'prune_heads', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_parameter', 'resize_token_embeddings', 'save_pretrained', 'set_input_embeddings', 'share_memory', 'state_dict', 'tie_weights', 'to', 'train', 'training', 'type', 'zero_grad']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "13\n",
      "torch.Size([1, 16, 768])\n"
     ]
    }
   ],
   "source": [
    "print(type(all_hidden_states))\n",
    "print(len(all_hidden_states))\n",
    "print(all_hidden_states[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(type(all_attentions))\n",
    "print(len(all_attentions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "print(all_attentions[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models are compatible with Torchscript\n",
    "model = model_class.from_pretrained(pretrained_weights, torchscript=True)\n",
    "traced_model = torch.jit.trace(model, (input_ids,))\n",
    "\n",
    "# Simple serialization for models and tokenizers\n",
    "model.save_pretrained('./directory/to/save/')  # save\n",
    "model = model_class.from_pretrained('./directory/to/save/')  # re-load\n",
    "tokenizer.save_pretrained('./directory/to/save/')  # save\n",
    "tokenizer = BertTokenizer.from_pretrained('./directory/to/save/')  # re-load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's encode some text in a sequence of hidden-states using each model:\n",
    "for model_class, tokenizer_class, pretrained_weights in MODELS:\n",
    "    # Load pretrained model/tokenizer\n",
    "    tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "    model = model_class.from_pretrained(pretrained_weights)\n",
    "\n",
    "    # Encode text\n",
    "    input_ids = torch.tensor([tokenizer.encode(\"Here is some text to encode\", add_special_tokens=True)])  # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(input_ids)[0]  # Models outputs are now tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the classes for an architecture can be initiated from pretrained weights for this architecture\n",
    "# Note that additional weights added for fine-tuning are only initialized\n",
    "# and need to be trained on the down-stream task\n",
    "pretrained_weights = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_class in BERT_MODEL_CLASSES:\n",
    "    # Load pretrained model/tokenizer\n",
    "    model = model_class.from_pretrained(pretrained_weights)\n",
    "\n",
    "    # Models can return full list of hidden-states & attentions weights at each layer\n",
    "    model = model_class.from_pretrained(pretrained_weights,\n",
    "                                        output_hidden_states=True,\n",
    "                                        output_attentions=True)\n",
    "    input_ids = torch.tensor([tokenizer.encode(\"Let's see all hidden-states and attentions on this text\")])\n",
    "    all_hidden_states, all_attentions = model(input_ids)[-2:]\n",
    "\n",
    "    # Models are compatible with Torchscript\n",
    "    model = model_class.from_pretrained(pretrained_weights, torchscript=True)\n",
    "    traced_model = torch.jit.trace(model, (input_ids,))\n",
    "\n",
    "    # Simple serialization for models and tokenizers\n",
    "    model.save_pretrained('./directory/to/save/')  # save\n",
    "    model = model_class.from_pretrained('./directory/to/save/')  # re-load\n",
    "    tokenizer.save_pretrained('./directory/to/save/')  # save\n",
    "    tokenizer = BertTokenizer.from_pretrained('./directory/to/save/')  # re-load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
