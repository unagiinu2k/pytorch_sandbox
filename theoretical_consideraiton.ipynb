{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "git add theoretical_consideraiton.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-981629d018e7>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-981629d018e7>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    git commit -a -m \"added theoretical_consideration\"\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "git commit -a -m \"added theoretical_consideration\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\text{時点$t$における$l$番目の(hidden) layerにおけるnode value}=h^{(l)}_t=f\\left(\n",
    "W^{(l)} \\left[\n",
    "a\n",
    "\\right]\n",
    "\\right\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* RNNはoption on optionのように考えると理解しやすい\n",
    "\n",
    "対応は以下のような感じか？\n",
    "\n",
    "* ひとつめのオプションに対してクーポンが入力される\n",
    "    * クーポンはembedded vectorになっている「ワード」なので300次元とかのイメージ \n",
    "    * なのでそれを受ける一つ目のオプションも300次元の入力を食えるようになっている\n",
    "    * 300次元は株価方向のラティスをイメージ？\n",
    "* ひとつめのオプションバリュー自体も300次元であれば株価イメージでいけるがかならずしも同じ次元である必要はない（よね？）\n",
    "    * その場合の対応するイメージは？？例えば200次元であれば、オプションンバリューのレイヤーは株価方向を粗視化しているとみなすのがいいか？\n",
    "        *そうだとするとそれってオプションプライシングでも応用可能かも？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gated RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU\n",
    "GRU の解説は\n",
    "https://mosko.tokyo/post/pytorch-rnn/\n",
    "\n",
    "上記文献の場合、\n",
    "* candidate node $n$が一番素朴なRNN(活性化関数を$\\tanh$としたもの)と自然に対応が付くノード\n",
    "    * ただし、RNNで素直に一時点前の同じレイヤーの隠れ層からの伝搬があるのに対して、GRUではreset gate $r$がゼロの時は伝搬を遮断する\n",
    "    * そのreset gateは普通のRNNスタイル（活性化関数はsigmoid）のノード\n",
    "         * ただし、一時点前のreset gateからの伝搬があるわけではなく、通常のhidden node $h$からの伝搬\n",
    "* update gate $z$が1になるときは　candidate nodeの値は捨てられて、一時点前の同じレイヤーがそのままスライド採用される\n",
    "    * これはGated RNNに由来する方法か\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNの設計のうち、オプション的な解釈がむずかしいかもしれないところ\n",
    "* ひとつめのオプションの現在価値と二つ目のオプションの1ステップ前（すなわち未来）とを混合してから活性化関数にかける\n",
    "    * ひとつめのオプション価値に依存するクーポンと思えばよいか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base2]",
   "language": "python",
   "name": "conda-env-base2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
